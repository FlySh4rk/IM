{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# First model\n",
    "\n",
    "This model is the simplest possible model we can think of. Inputs will be the list of points delimiting the bone and tooth area and their squares and cross-products to account for second order contributions.\n",
    "\n",
    "The outputs will be the coordinates of optimal axe.\n",
    "\n",
    "The cost function is the distance of the two points. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3de550a69617c8cb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## First step: load and prepare the datasets\n",
    "\n",
    "Loads the datasets prepared by the `dataset_gen` notebook, then prepare the input by appending all the cross-products."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "938aee1480f6e9d0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import datadir\n",
    "\n",
    "input_dataset = pd.read_pickle(datadir(\"input_rot.pkl\"))\n",
    "output_dataset = pd.read_pickle(datadir(\"output_rot.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:05.199410Z",
     "start_time": "2023-12-30T23:37:05.147566Z"
    }
   },
   "id": "cacafe54430c25cc",
   "execution_count": 422
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1         2         3         4         5         6   \\\n0    0.516425  1.904407  2.830124 -1.441737  1.326225 -2.493799 -1.174322   \n1    0.190749  2.636898  1.990407 -1.145306 -0.084083 -1.826785 -1.415641   \n2    0.763316  2.400042  0.899236 -1.236279 -1.067384 -1.680220 -1.266553   \n3    2.721627  0.011318 -0.064539 -3.122918 -1.379603 -1.771914  0.969613   \n4    1.358551  2.593314  1.815764 -1.247205  0.037793 -1.679343 -0.809907   \n..        ...       ...       ...       ...       ...       ...       ...   \n995 -1.561810  2.416841  1.728431 -0.158547  0.361340 -1.620670 -2.655468   \n996  2.516807  1.616279  0.044194 -1.592231 -1.548466 -0.247470  0.992358   \n997 -0.266827  2.010331  0.778407 -1.728121 -0.968680 -2.406388 -2.333855   \n998 -0.218928  3.232466  1.253863 -0.662542 -0.875507 -1.191209 -1.891129   \n999  0.212402  2.626018  2.905755 -0.774124  1.318446 -1.707187 -1.224435   \n\n           7         8         9         10        11        12        13  \\\n0    0.549347 -0.698353  3.384424  0.434217  1.870214 -1.092114  0.583540   \n1    1.752770 -0.374559  4.436448  0.207304  2.576463 -1.432195  1.813204   \n2    2.676438  0.577066  4.476345  0.834169  2.682152 -1.337407  2.394327   \n3    1.228005  3.831253  1.451021  2.677371  0.037996  1.013869  1.201328   \n4    2.372996  0.934270  4.690807  1.261360  2.574946 -0.712716  2.391365   \n..        ...       ...       ...       ...       ...       ...       ...   \n995  0.725439 -2.947575  3.593161 -1.616090  2.356256 -2.601187  0.786025   \n996  2.778237  3.876662  3.173724  2.444416  1.525986  1.064749  2.868529   \n997  1.483393 -0.849080  3.906419 -0.447146  2.096965 -2.153536  1.396759   \n998  2.516926 -0.694903  5.077147 -0.136472  3.195135 -1.973586  2.554258   \n999  0.940964 -1.124529  4.022585  0.315511  2.365529 -1.327544  1.201453   \n\n           14        15  \n0   -2.366667  2.263976  \n1   -2.415939  3.634099  \n2   -1.247849  4.596625  \n3    2.427678  2.855380  \n4   -1.038083  4.221932  \n..        ...       ...  \n995 -4.423227  2.009868  \n996  2.139221  4.337900  \n997 -2.956806  3.401421  \n998 -2.659362  4.473817  \n999 -2.505620  2.568544  \n\n[1000 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.516425</td>\n      <td>1.904407</td>\n      <td>2.830124</td>\n      <td>-1.441737</td>\n      <td>1.326225</td>\n      <td>-2.493799</td>\n      <td>-1.174322</td>\n      <td>0.549347</td>\n      <td>-0.698353</td>\n      <td>3.384424</td>\n      <td>0.434217</td>\n      <td>1.870214</td>\n      <td>-1.092114</td>\n      <td>0.583540</td>\n      <td>-2.366667</td>\n      <td>2.263976</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.190749</td>\n      <td>2.636898</td>\n      <td>1.990407</td>\n      <td>-1.145306</td>\n      <td>-0.084083</td>\n      <td>-1.826785</td>\n      <td>-1.415641</td>\n      <td>1.752770</td>\n      <td>-0.374559</td>\n      <td>4.436448</td>\n      <td>0.207304</td>\n      <td>2.576463</td>\n      <td>-1.432195</td>\n      <td>1.813204</td>\n      <td>-2.415939</td>\n      <td>3.634099</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.763316</td>\n      <td>2.400042</td>\n      <td>0.899236</td>\n      <td>-1.236279</td>\n      <td>-1.067384</td>\n      <td>-1.680220</td>\n      <td>-1.266553</td>\n      <td>2.676438</td>\n      <td>0.577066</td>\n      <td>4.476345</td>\n      <td>0.834169</td>\n      <td>2.682152</td>\n      <td>-1.337407</td>\n      <td>2.394327</td>\n      <td>-1.247849</td>\n      <td>4.596625</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.721627</td>\n      <td>0.011318</td>\n      <td>-0.064539</td>\n      <td>-3.122918</td>\n      <td>-1.379603</td>\n      <td>-1.771914</td>\n      <td>0.969613</td>\n      <td>1.228005</td>\n      <td>3.831253</td>\n      <td>1.451021</td>\n      <td>2.677371</td>\n      <td>0.037996</td>\n      <td>1.013869</td>\n      <td>1.201328</td>\n      <td>2.427678</td>\n      <td>2.855380</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.358551</td>\n      <td>2.593314</td>\n      <td>1.815764</td>\n      <td>-1.247205</td>\n      <td>0.037793</td>\n      <td>-1.679343</td>\n      <td>-0.809907</td>\n      <td>2.372996</td>\n      <td>0.934270</td>\n      <td>4.690807</td>\n      <td>1.261360</td>\n      <td>2.574946</td>\n      <td>-0.712716</td>\n      <td>2.391365</td>\n      <td>-1.038083</td>\n      <td>4.221932</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>-1.561810</td>\n      <td>2.416841</td>\n      <td>1.728431</td>\n      <td>-0.158547</td>\n      <td>0.361340</td>\n      <td>-1.620670</td>\n      <td>-2.655468</td>\n      <td>0.725439</td>\n      <td>-2.947575</td>\n      <td>3.593161</td>\n      <td>-1.616090</td>\n      <td>2.356256</td>\n      <td>-2.601187</td>\n      <td>0.786025</td>\n      <td>-4.423227</td>\n      <td>2.009868</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>2.516807</td>\n      <td>1.616279</td>\n      <td>0.044194</td>\n      <td>-1.592231</td>\n      <td>-1.548466</td>\n      <td>-0.247470</td>\n      <td>0.992358</td>\n      <td>2.778237</td>\n      <td>3.876662</td>\n      <td>3.173724</td>\n      <td>2.444416</td>\n      <td>1.525986</td>\n      <td>1.064749</td>\n      <td>2.868529</td>\n      <td>2.139221</td>\n      <td>4.337900</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>-0.266827</td>\n      <td>2.010331</td>\n      <td>0.778407</td>\n      <td>-1.728121</td>\n      <td>-0.968680</td>\n      <td>-2.406388</td>\n      <td>-2.333855</td>\n      <td>1.483393</td>\n      <td>-0.849080</td>\n      <td>3.906419</td>\n      <td>-0.447146</td>\n      <td>2.096965</td>\n      <td>-2.153536</td>\n      <td>1.396759</td>\n      <td>-2.956806</td>\n      <td>3.401421</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>-0.218928</td>\n      <td>3.232466</td>\n      <td>1.253863</td>\n      <td>-0.662542</td>\n      <td>-0.875507</td>\n      <td>-1.191209</td>\n      <td>-1.891129</td>\n      <td>2.516926</td>\n      <td>-0.694903</td>\n      <td>5.077147</td>\n      <td>-0.136472</td>\n      <td>3.195135</td>\n      <td>-1.973586</td>\n      <td>2.554258</td>\n      <td>-2.659362</td>\n      <td>4.473817</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>0.212402</td>\n      <td>2.626018</td>\n      <td>2.905755</td>\n      <td>-0.774124</td>\n      <td>1.318446</td>\n      <td>-1.707187</td>\n      <td>-1.224435</td>\n      <td>0.940964</td>\n      <td>-1.124529</td>\n      <td>4.022585</td>\n      <td>0.315511</td>\n      <td>2.365529</td>\n      <td>-1.327544</td>\n      <td>1.201453</td>\n      <td>-2.505620</td>\n      <td>2.568544</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 16 columns</p>\n</div>"
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:05.214967Z",
     "start_time": "2023-12-30T23:37:05.205806Z"
    }
   },
   "id": "3942eeda3110b9bd",
   "execution_count": 423
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3\n0    1.275800 -0.902886 -0.930729  2.025539\n1    0.431293 -0.259086 -1.003847  3.115054\n2   -0.139922 -0.126086 -0.293505  3.537362\n3    0.133826 -1.425057  2.487543  1.386431\n4    0.709293 -0.147797  0.111208  3.469762\n..        ...       ...       ...       ...\n995 -0.006289 -0.069359 -2.897020  2.186327\n996  0.083437  0.119185  2.381262  2.976535\n997 -0.496871 -0.795882 -1.601642  2.700391\n998 -0.225558  0.340315 -1.366081  3.825089\n999  1.239395 -0.232607 -1.160545  2.539528\n\n[1000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.275800</td>\n      <td>-0.902886</td>\n      <td>-0.930729</td>\n      <td>2.025539</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.431293</td>\n      <td>-0.259086</td>\n      <td>-1.003847</td>\n      <td>3.115054</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.139922</td>\n      <td>-0.126086</td>\n      <td>-0.293505</td>\n      <td>3.537362</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.133826</td>\n      <td>-1.425057</td>\n      <td>2.487543</td>\n      <td>1.386431</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.709293</td>\n      <td>-0.147797</td>\n      <td>0.111208</td>\n      <td>3.469762</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>-0.006289</td>\n      <td>-0.069359</td>\n      <td>-2.897020</td>\n      <td>2.186327</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>0.083437</td>\n      <td>0.119185</td>\n      <td>2.381262</td>\n      <td>2.976535</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>-0.496871</td>\n      <td>-0.795882</td>\n      <td>-1.601642</td>\n      <td>2.700391</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>-0.225558</td>\n      <td>0.340315</td>\n      <td>-1.366081</td>\n      <td>3.825089</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>1.239395</td>\n      <td>-0.232607</td>\n      <td>-1.160545</td>\n      <td>2.539528</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:05.215527Z",
     "start_time": "2023-12-30T23:37:05.210293Z"
    }
   },
   "id": "6ccf8c558c383b94",
   "execution_count": 424
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Iterator\n",
    "from itertools import permutations\n",
    "\n",
    "\n",
    "def shuffle_points(s: np.ndarray) -> Iterator[np.ndarray]:\n",
    "    for p1 in permutations(range(4)):\n",
    "        for p2 in permutations(range(4, 8)):\n",
    "            yield np.array(\n",
    "                [[s[i * 2], s[i * 2 + 1]] for i in p1] + [[s[i * 2], s[i * 2 + 1]] for i in\n",
    "                                                          p2]).reshape(-1)\n",
    "\n",
    "\n",
    "from utils import add_cross_prods\n",
    "\n",
    "\n",
    "def prepare_input(orig: pd.DataFrame) -> Iterator[np.ndarray]:\n",
    "    for row in orig.to_numpy():\n",
    "        for s in shuffle_points(row):\n",
    "            x = add_cross_prods(s)\n",
    "            yield x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:05.235414Z",
     "start_time": "2023-12-30T23:37:05.216438Z"
    }
   },
   "id": "24a664ad7b3e6a73",
   "execution_count": 425
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prepared_input = np.array([r for r in prepare_input(input_dataset)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.506523Z",
     "start_time": "2023-12-30T23:37:05.231055Z"
    }
   },
   "id": "da1142f683bdc59b",
   "execution_count": 426
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.51642464,  1.90440743,  2.83012391, ..., -1.38104511,\n         1.32112082, -5.35807582],\n       [ 0.51642464,  1.90440743,  2.83012391, ..., -2.47252066,\n         1.32112082, -0.63729269],\n       [ 0.51642464,  1.90440743,  2.83012391, ..., -4.42617395,\n         4.23411988, -5.35807582],\n       ...,\n       [-1.22443494,  0.94096412,  1.3184459 , ..., -1.3510691 ,\n         4.83294919, -4.52351324],\n       [-1.22443494,  0.94096412,  1.3184459 , ...,  1.26917144,\n         9.51554081,  0.7463512 ],\n       [-1.22443494,  0.94096412,  1.3184459 , ..., -2.66010518,\n         9.51554081, -4.52351324]])"
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepared_input"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.513343Z",
     "start_time": "2023-12-30T23:37:19.507367Z"
    }
   },
   "id": "89c8133e814e381c",
   "execution_count": 427
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "136"
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = prepared_input.shape[1]\n",
    "input_dim"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.513810Z",
     "start_time": "2023-12-30T23:37:19.510725Z"
    }
   },
   "id": "161c70ae2d26f93",
   "execution_count": 428
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 4)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(576000, 4)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "4"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prepared_output = output_dataset.to_numpy()\n",
    "display(prepared_output.shape)\n",
    "prepared_output = np.repeat(prepared_output, repeats=576, axis=0)\n",
    "output_dim = prepared_output.shape[1]\n",
    "display(prepared_output.shape)\n",
    "display(output_dim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.522772Z",
     "start_time": "2023-12-30T23:37:19.514984Z"
    }
   },
   "id": "2a1f4c43038deaf2",
   "execution_count": 429
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now prepare the network\n",
    "\n",
    "Only one layer with linear output."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a9910db0546cafb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(None, 4)"
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(input_dim))\n",
    "model.add(tf.keras.layers.Dense(units=output_dim, activation=tf.keras.activations.linear))\n",
    "model.output_shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.555881Z",
     "start_time": "2023-12-30T23:37:19.521441Z"
    }
   },
   "id": "a3d598692958d159",
   "execution_count": 430
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Test the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba5ec469dde460f1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(576000, 4), dtype=float32, numpy=\narray([[  5.1302958 ,  -0.14054108,  -6.0109935 ,  -5.4307156 ],\n       [  6.230429  ,   0.8472626 ,  -3.992612  ,  -4.4352913 ],\n       [ 10.345779  ,   2.3973393 ,  -8.815542  ,  -7.1777644 ],\n       ...,\n       [ -1.9467354 ,  -1.1453438 ,  -0.2736677 ,  -5.1018724 ],\n       [  0.8226056 ,   0.8773762 ,  -0.66226226,  -9.36401   ],\n       [  1.1467433 ,   0.6006789 ,  -3.378408  , -10.390437  ]],\n      dtype=float32)>"
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(prepared_input)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.795337Z",
     "start_time": "2023-12-30T23:37:19.533590Z"
    }
   },
   "id": "28ddd0cd2f57bed4",
   "execution_count": 431
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Optimizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79c631bf8bdce81f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.800819Z",
     "start_time": "2023-12-30T23:37:19.795735Z"
    }
   },
   "id": "39c390b05f3447dd",
   "execution_count": 432
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.805920Z",
     "start_time": "2023-12-30T23:37:19.799927Z"
    }
   },
   "id": "e271e5d8972d7487",
   "execution_count": 433
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Setup training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2d6fbe663dc82ce"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, outputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # training=True is only needed if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_function(outputs, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.816406Z",
     "start_time": "2023-12-30T23:37:19.812412Z"
    }
   },
   "id": "55733171820f9766",
   "execution_count": 434
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(inputs, outputs):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(inputs, training=False)\n",
    "    t_loss = loss_function(outputs, predictions)\n",
    "\n",
    "    test_loss(t_loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:37:19.828319Z",
     "start_time": "2023-12-30T23:37:19.817176Z"
    }
   },
   "id": "46bda14d8425416c",
   "execution_count": 435
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Do the training\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89aa9eb20341a24b"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 3.941657304763794, Test Loss: 0.2813047468662262, \n",
      "Epoch 2, Loss: 0.12253496795892715, Test Loss: 0.048918984830379486, \n",
      "Epoch 3, Loss: 0.029688764363527298, Test Loss: 0.018002379685640335, \n",
      "Epoch 4, Loss: 0.0132948849350214, Test Loss: 0.009924303740262985, \n",
      "Epoch 5, Loss: 0.007997432723641396, Test Loss: 0.006466185208410025, \n",
      "Epoch 6, Loss: 0.0052755605429410934, Test Loss: 0.00424009608104825, \n",
      "Epoch 7, Loss: 0.0035119131207466125, Test Loss: 0.002839587861672044, \n",
      "Epoch 8, Loss: 0.002331543480977416, Test Loss: 0.0018800374818965793, \n",
      "Epoch 9, Loss: 0.0015296217752620578, Test Loss: 0.0012319101952016354, \n",
      "Epoch 10, Loss: 0.0009803175926208496, Test Loss: 0.0007638655952177942, \n",
      "Epoch 11, Loss: 0.0006069033988751471, Test Loss: 0.00046065551578067243, \n",
      "Epoch 12, Loss: 0.0003590752021409571, Test Loss: 0.0002669190871529281, \n",
      "Epoch 13, Loss: 0.00020365294767543674, Test Loss: 0.00015154034190345556, \n",
      "Epoch 14, Loss: 0.00011354265006957576, Test Loss: 8.979129779618233e-05, \n",
      "Epoch 15, Loss: 6.751604814780876e-05, Test Loss: 7.743835885776207e-05, \n",
      "Epoch 16, Loss: 5.127553595229983e-05, Test Loss: 4.592152254190296e-05, \n",
      "Epoch 17, Loss: 4.255403109709732e-05, Test Loss: 3.885359183186665e-05, \n",
      "Epoch 18, Loss: 4.0809194615576416e-05, Test Loss: 4.51286650786642e-05, \n",
      "Epoch 19, Loss: 4.142026591580361e-05, Test Loss: 3.446809569140896e-05, \n",
      "Epoch 20, Loss: 3.575661685317755e-05, Test Loss: 3.655700129456818e-05, \n",
      "Epoch 21, Loss: 3.4604654501890764e-05, Test Loss: 4.8066562158055604e-05, \n",
      "Epoch 22, Loss: 4.2229556129314005e-05, Test Loss: 3.048459802812431e-05, \n",
      "Epoch 23, Loss: 2.2559395802090876e-05, Test Loss: 1.676765168667771e-05, \n",
      "Epoch 24, Loss: 2.876500366255641e-05, Test Loss: 1.6327243429259397e-05, \n",
      "Epoch 25, Loss: 3.0570670787710696e-05, Test Loss: 3.57544377038721e-05, \n",
      "Epoch 26, Loss: 2.9680088118766434e-05, Test Loss: 1.3586009117716458e-05, \n",
      "Epoch 27, Loss: 2.5195384296239354e-05, Test Loss: 6.936675617907895e-06, \n",
      "Epoch 28, Loss: 2.0488258087425493e-05, Test Loss: 8.839401743898634e-06, \n",
      "Epoch 29, Loss: 2.6548914320301265e-05, Test Loss: 1.0275487511535175e-05, \n",
      "Epoch 30, Loss: 2.5961126084439456e-05, Test Loss: 1.5943816833896562e-05, \n",
      "Epoch 31, Loss: 2.8112004656577483e-05, Test Loss: 2.4866085368557833e-05, \n",
      "Epoch 32, Loss: 2.5594184990040958e-05, Test Loss: 1.776610247361532e-06, \n",
      "Epoch 33, Loss: 2.3905236957943998e-05, Test Loss: 2.8329991437203716e-06, \n",
      "Epoch 34, Loss: 2.706728264456615e-05, Test Loss: 1.2016733307973482e-05, \n",
      "Epoch 35, Loss: 2.1506099074031226e-05, Test Loss: 4.450160849955864e-05, \n",
      "Epoch 36, Loss: 2.5443661797908135e-05, Test Loss: 1.7162185031338595e-05, \n",
      "Epoch 37, Loss: 2.1309944713721052e-05, Test Loss: 4.386571526993066e-05, \n",
      "Epoch 38, Loss: 2.7577998480410315e-05, Test Loss: 4.9684651457937434e-05, \n",
      "Epoch 39, Loss: 2.7943868190050125e-05, Test Loss: 4.004941274615703e-06, \n",
      "Epoch 40, Loss: 2.6121233531739563e-05, Test Loss: 4.706141407950781e-05, \n",
      "Epoch 41, Loss: 1.9641980543383397e-05, Test Loss: 5.957181201665662e-06, \n",
      "Epoch 42, Loss: 2.9953056582598947e-05, Test Loss: 8.699783393240068e-06, \n",
      "Epoch 43, Loss: 2.6484682166483253e-05, Test Loss: 7.5133784775971435e-06, \n",
      "Epoch 44, Loss: 1.8263212041347288e-05, Test Loss: 1.45463741318963e-06, \n",
      "Epoch 45, Loss: 3.1233812478603795e-05, Test Loss: 3.9702848880551755e-05, \n",
      "Epoch 46, Loss: 2.6674626496969722e-05, Test Loss: 1.246151532541262e-05, \n",
      "Epoch 47, Loss: 2.056196899502538e-05, Test Loss: 1.6218380551435985e-05, \n",
      "Epoch 48, Loss: 2.6159421395277604e-05, Test Loss: 5.635487923427718e-06, \n",
      "Epoch 49, Loss: 1.8890950741479173e-05, Test Loss: 1.393076490785461e-05, \n",
      "Epoch 50, Loss: 2.8675012799794786e-05, Test Loss: 3.0478222470264882e-05, \n",
      "Epoch 51, Loss: 2.293262332386803e-05, Test Loss: 9.587848580849823e-06, \n",
      "Epoch 52, Loss: 2.7527858037501574e-05, Test Loss: 6.25622269581072e-05, \n",
      "Epoch 53, Loss: 2.996618059114553e-05, Test Loss: 3.5653632949106395e-05, \n",
      "Epoch 54, Loss: 2.5717468815855682e-05, Test Loss: 2.409545913906186e-06, \n",
      "Epoch 55, Loss: 2.3358186808764003e-05, Test Loss: 7.15519636287354e-05, \n",
      "Epoch 56, Loss: 1.8932047169073485e-05, Test Loss: 3.067314173677005e-05, \n",
      "Epoch 57, Loss: 2.8212612960487604e-05, Test Loss: 1.9433993657003157e-05, \n",
      "Epoch 58, Loss: 2.6536505174590275e-05, Test Loss: 6.428581400541589e-07, \n",
      "Epoch 59, Loss: 3.460570587776601e-05, Test Loss: 5.736284947488457e-05, \n",
      "Epoch 60, Loss: 1.3252095413918141e-05, Test Loss: 1.590117608429864e-05, \n",
      "Epoch 61, Loss: 2.9498691219487227e-05, Test Loss: 1.7029371520038694e-05, \n",
      "Epoch 62, Loss: 2.6469369913684204e-05, Test Loss: 1.694002639851533e-05, \n",
      "Epoch 63, Loss: 2.1259900677250698e-05, Test Loss: 1.3476798130795942e-06, \n",
      "Epoch 64, Loss: 2.2114398234407417e-05, Test Loss: 1.965420597116463e-05, \n",
      "Epoch 65, Loss: 2.7489564672578126e-05, Test Loss: 8.988138870336115e-05, \n",
      "Epoch 66, Loss: 2.5078181352000684e-05, Test Loss: 2.1741418549936498e-06, \n",
      "Epoch 67, Loss: 2.6251016606693156e-05, Test Loss: 1.0541196388658136e-05, \n",
      "Epoch 68, Loss: 2.2402175090974197e-05, Test Loss: 4.784856173500884e-06, \n",
      "Epoch 69, Loss: 3.5969798773294315e-05, Test Loss: 6.61421290715225e-05, \n",
      "Epoch 70, Loss: 2.4375338398385793e-05, Test Loss: 7.975177140906453e-06, \n",
      "Epoch 71, Loss: 1.5199160770862363e-05, Test Loss: 1.2632614925678354e-05, \n",
      "Epoch 72, Loss: 2.2455531507148407e-05, Test Loss: 3.5664170354721136e-06, \n",
      "Epoch 73, Loss: 3.0633280402980745e-05, Test Loss: 1.8462419575371314e-06, \n",
      "Epoch 74, Loss: 2.06742715818109e-05, Test Loss: 0.0001014733497868292, \n",
      "Epoch 75, Loss: 2.9563572752522305e-05, Test Loss: 4.214698947180295e-06, \n",
      "Epoch 76, Loss: 2.0760709958267398e-05, Test Loss: 2.7584030704019824e-06, \n",
      "Epoch 77, Loss: 2.1274066966725513e-05, Test Loss: 3.148528776364401e-05, \n",
      "Epoch 78, Loss: 2.45105147769209e-05, Test Loss: 6.297137588262558e-06, \n",
      "Epoch 79, Loss: 2.4387942175962962e-05, Test Loss: 6.667988782282919e-05, \n",
      "Epoch 80, Loss: 2.6939038434647955e-05, Test Loss: 3.381002170499414e-05, \n",
      "Epoch 81, Loss: 3.087893855990842e-05, Test Loss: 1.401660938427085e-05, \n",
      "Epoch 82, Loss: 1.8657319742487743e-05, Test Loss: 1.5142623851716053e-05, \n",
      "Epoch 83, Loss: 2.7504011086421087e-05, Test Loss: 5.3109994041733444e-05, \n",
      "Epoch 84, Loss: 2.3940339815453626e-05, Test Loss: 4.5870565372752026e-06, \n",
      "Epoch 85, Loss: 2.1746665879618376e-05, Test Loss: 5.814129690406844e-05, \n",
      "Epoch 86, Loss: 2.7504882382345386e-05, Test Loss: 9.601725651009474e-06, \n",
      "Epoch 87, Loss: 1.872797656687908e-05, Test Loss: 7.577825726912124e-06, \n",
      "Epoch 88, Loss: 3.37849669449497e-05, Test Loss: 5.813686243527627e-07, \n",
      "Epoch 89, Loss: 2.4153630874934606e-05, Test Loss: 3.345482582517434e-06, \n",
      "Epoch 90, Loss: 2.707401836232748e-05, Test Loss: 7.065662066452205e-05, \n",
      "Epoch 91, Loss: 2.7557965950109065e-05, Test Loss: 2.5601366360206157e-05, \n",
      "Epoch 92, Loss: 1.5258519852068275e-05, Test Loss: 3.93913833249826e-05, \n",
      "Epoch 93, Loss: 3.022410237463191e-05, Test Loss: 0.00011971730418736115, \n",
      "Epoch 94, Loss: 2.4389144527958706e-05, Test Loss: 9.176868843496777e-06, \n",
      "Epoch 95, Loss: 2.3237143977894448e-05, Test Loss: 1.1933233508898411e-05, \n",
      "Epoch 96, Loss: 2.3326840164372697e-05, Test Loss: 6.495172783615999e-06, \n",
      "Epoch 97, Loss: 2.942389801319223e-05, Test Loss: 3.770262992475182e-05, \n",
      "Epoch 98, Loss: 2.818575558194425e-05, Test Loss: 5.516150122275576e-05, \n",
      "Epoch 99, Loss: 2.1543881302932277e-05, Test Loss: 1.1769462616939563e-05, \n",
      "Epoch 100, Loss: 2.8893304261146113e-05, Test Loss: 1.2093998520867899e-05, \n"
     ]
    },
    {
     "data": {
      "text/plain": "      Train Loss  Test Loss\n0    1000.000000  73.931671\n1       3.941657   0.281305\n2       0.122535   0.048919\n3       0.029689   0.018002\n4       0.013295   0.009924\n..           ...        ...\n96      0.000023   0.000006\n97      0.000029   0.000038\n98      0.000028   0.000055\n99      0.000022   0.000012\n100     0.000029   0.000012\n\n[101 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train Loss</th>\n      <th>Test Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000.000000</td>\n      <td>73.931671</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.941657</td>\n      <td>0.281305</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.122535</td>\n      <td>0.048919</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.029689</td>\n      <td>0.018002</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.013295</td>\n      <td>0.009924</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>0.000023</td>\n      <td>0.000006</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.000029</td>\n      <td>0.000038</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>0.000028</td>\n      <td>0.000055</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.000022</td>\n      <td>0.000012</td>\n    </tr>\n    <tr>\n      <th>100</th>\n      <td>0.000029</td>\n      <td>0.000012</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "\n",
    "def train_model(EPOCHS=100, BATCH_SIZE=1000) -> pd.DataFrame:\n",
    "    stats = pd.DataFrame(columns=[\"Train Loss\", \"Test Loss\"])\n",
    "    train_losses = np.ndarray(shape=[1])\n",
    "    test_losses = np.ndarray(shape=[1])\n",
    "\n",
    "    def init_epoch(inpts: np.ndarray, outs: np.ndarray) -> Tuple[\n",
    "        Iterator[Tuple[tf.Tensor, tf.Tensor]], Iterator[Tuple[tf.Tensor, tf.Tensor]]]:\n",
    "        indexes = np.arange(inpts.shape[0])\n",
    "        np.random.shuffle(indexes)\n",
    "        train_size = math.ceil(inpts.shape[0] * 9 / 10)\n",
    "        train_indexes = indexes[0:train_size]\n",
    "        test_indexes = indexes[train_size:-1]\n",
    "\n",
    "        def read_batches(idx: np.ndarray, bs=BATCH_SIZE) -> Iterator[Tuple[tf.Tensor, tf.Tensor]]:\n",
    "            for i in range(0, idx.shape[0], bs):\n",
    "                ii = idx[i:(i + bs)]\n",
    "                yield tf.convert_to_tensor(inpts[ii]), tf.convert_to_tensor(\n",
    "                    outs[ii])\n",
    "\n",
    "        return read_batches(train_indexes), read_batches(test_indexes)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        test_loss.reset_states()\n",
    "\n",
    "        train_ds, test_ds = init_epoch(prepared_input, prepared_output)\n",
    "\n",
    "        for inputs, outputs in train_ds:\n",
    "            train_step(inputs, outputs)\n",
    "\n",
    "        for test_inputs, test_outputs in test_ds:\n",
    "            test_step(test_inputs, test_outputs)\n",
    "\n",
    "        train_losses = np.append(train_losses, [train_loss.result().numpy()])\n",
    "        test_losses = np.append(test_losses, [test_loss.result().numpy()])\n",
    "\n",
    "        if (epoch % 1 == 0):\n",
    "            print(\n",
    "                f'Epoch {epoch + 1}, '\n",
    "                f'Loss: {train_loss.result()}, '\n",
    "                f'Test Loss: {test_loss.result()}, '\n",
    "            )\n",
    "\n",
    "    stats[\"Train Loss\"] = train_losses\n",
    "    stats[\"Test Loss\"] = test_losses\n",
    "    return stats\n",
    "\n",
    "\n",
    "stats = train_model()\n",
    "display(stats)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:40:44.310604Z",
     "start_time": "2023-12-30T23:37:19.829237Z"
    }
   },
   "id": "c1a06e881136ca46",
   "execution_count": 436
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plot stats"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4eebdfda2c53bd5a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: >"
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "stats.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:40:44.375686Z",
     "start_time": "2023-12-30T23:40:44.315238Z"
    }
   },
   "id": "f26f5524b6ba23c8",
   "execution_count": 437
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Some random tests"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6371628c36843ede"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  2, -1,  2, -1,  1])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([ 1,  1, -1,  1, -1, -1,  1, -1,  1,  1,  1,  2, -1,  2, -1,  1,  1,\n       -1,  1, -1, -1,  1, -1,  1,  1,  1,  2, -1,  2, -1,  1, -1,  1, -1,\n       -1,  1, -1,  1,  1,  1,  2, -1,  2, -1,  1, -1,  1,  1, -1,  1, -1,\n       -1, -1, -2,  1, -2,  1, -1, -1, -1,  1, -1,  1,  1,  1,  2, -1,  2,\n       -1,  1,  1, -1,  1, -1, -1, -1, -2,  1, -2,  1, -1, -1,  1, -1, -1,\n       -1, -2,  1, -2,  1, -1, -1,  1,  1,  1,  2, -1,  2, -1,  1, -1, -1,\n       -1, -2,  1, -2,  1, -1,  1,  1,  2, -1,  2, -1,  1,  1,  2, -1,  2,\n       -1,  1,  2, -1,  2, -1,  1, -2,  4, -2,  2, -2,  1, -1, -2,  2, -1])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(1, 4), dtype=float32, numpy=\narray([[-0.08553331, -0.3498712 ,  0.09662097,  1.5551661 ]],\n      dtype=float32)>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s1 = np.array([1, 1, -1, 1, -1, -1, 1, -1, 1, 1, 1, 2, -1, 2, -1, 1])\n",
    "display(s1)\n",
    "s1 = add_cross_prods(s1)\n",
    "display(s1)\n",
    "r1 = model(s1.reshape(1, -1))\n",
    "display(r1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:40:44.391413Z",
     "start_time": "2023-12-30T23:40:44.374992Z"
    }
   },
   "id": "2d7fb58e982f6341",
   "execution_count": 438
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.08553331, -0.3498712 ,  0.09662097,  1.5551661 ]],\n      dtype=float32)"
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:40:44.391934Z",
     "start_time": "2023-12-30T23:40:44.382538Z"
    }
   },
   "id": "3d6d4284232bbefa",
   "execution_count": 439
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_rot/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_rot/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(datadir(\"model_rot\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-30T23:40:44.632844Z",
     "start_time": "2023-12-30T23:40:44.385665Z"
    }
   },
   "id": "d5c6fb35a49586d1",
   "execution_count": 440
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
